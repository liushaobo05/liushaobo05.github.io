<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kubernetes学习笔记1]]></title>
    <url>%2F2018%2F05%2F22%2Fkubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%2F</url>
    <content type="text"><![CDATA[从helloworld入手学习一项IT新技术，都会从helloworld起步，那么k8s的helloworld是什么样子呢？运行一个hello world首先要安装针对这项技术的IT环境，在本机安装minikube的单点集群实验。 我们将按照以下几步进行展开 创建一个集群 部署一个应用 创建service，外部访问 伸缩应用副本 版本回退 集群管理通过minikube安装的单节点的集群，首先通过minikube 创建一个集群12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849$minikube versionminikube version: v0.23.0Usage: minikube [command]Available Commands: addons Modify minikube&apos;s kubernetes addons completion Outputs minikube shell completion for the given shell (bash) config Modify minikube config dashboard Opens/displays the kubernetes dashboard URL for your local cluster delete Deletes a local kubernetes cluster docker-env Sets up docker env variables; similar to &apos;$(docker-machine env)&apos; get-k8s-versions Gets the list of available kubernetes versions available for minikube ip Retrieves the IP address of the running cluster logs Gets the logs of the running localkube instance, used for debugging minikube, not user code mount Mounts the specified directory into minikube profile Profile sets the current minikube profile service Gets the kubernetes URL(s) for the specified service in your local cluster ssh Log into or run a command on a machine with SSH; similar to &apos;docker-machine ssh&apos; ssh-key Retrieve the ssh identity key path of the specified cluster start Starts a local kubernetes cluster status Gets the status of a local kubernetes cluster stop Stops a running local kubernetes cluster update-context Verify the IP address of the running cluster in kubeconfig. version Print the version of minikube# 1. 启动一个集群$minikube startStarting local Kubernetes v1.8.0 cluster...Starting VM...Getting VM IP address...Moving files into cluster...Setting up certs...Connecting to cluster...Setting up kubeconfig...Starting cluster components...Kubectl is now configured to use the cluster.# 2. 获取集群版本$kubectl versionClient Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;8&quot;, GitVersion:&quot;v1.8.4&quot;, GitCommit:&quot;9befc2b8928a9426501d3bf62f72849d5cbcd5a3&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2017-11-20T19:11:22Z&quot;, GoVersion:&quot;go1.9.2&quot;, Compiler:&quot;gc&quot;, Platform:&quot;darwin/amd64&quot;&#125;Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;8&quot;, GitVersion:&quot;v1.8.0&quot;, GitCommit:&quot;0b9efaeb34a2fc51ff8e4d34ad9bc6375459c4a4&quot;, GitTreeState:&quot;dirty&quot;, BuildDate:&quot;2017-10-17T15:09:55Z&quot;, GoVersion:&quot;go1.8.3&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;# 3. 查看当前集群信息$kubectl cluster-info# 3. 获取节点信息$kubectl get nodes 应用部署部署一个nigix容器12345678910111213141516171819202122232425262728293031$kubectl run my-nginx --image=nginx --port=80# 2. 查看deployment$kubectl get deployments# 3. 设置集群内部网路代理$kubectl proxy# 4. 查看代理信息$curl http://localhost:8001/version&#123; &quot;major&quot;: &quot;1&quot;, &quot;minor&quot;: &quot;8&quot;, &quot;gitVersion&quot;: &quot;v1.8.0&quot;, &quot;gitCommit&quot;: &quot;0b9efaeb34a2fc51ff8e4d34ad9bc6375459c4a4&quot;, &quot;gitTreeState&quot;: &quot;dirty&quot;, &quot;buildDate&quot;: &quot;2017-10-17T15:09:55Z&quot;, &quot;goVersion&quot;: &quot;go1.8.3&quot;, &quot;compiler&quot;: &quot;gc&quot;, &quot;platform&quot;: &quot;linux/amd64&quot;&#125;# 5. pod name$export POD_NAME=$(kubectl get pods -o go-template --template &apos;&#123;&#123;range .items&#125;&#125;&#123;&#123;.metadata.name&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&apos;)echo Name of the Pod: $POD_NAME# 6. 访问请求$curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/# 7. 进入容器$kubectl exec -ti $POD_NAME bash 创建service123456789# 创建service$kubectl expose deployment my-nginx --type=&quot;NodePort&quot; --port 80# 设置环境变量$export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=&apos;&#123;&#123;(index .spec.ports 0).nodePort&#125;&#125;&apos;)$echo NODE_PORT=$NODE_PORT＃ 测试$curl $(minikube ip):$NODE_PORT 伸缩应用1234567# 伸缩应用$kubectl scale deployments/my-nginx --replicas=4# 查看节点$kubectl get pods -o wide# kubectl scale deployments/my-nginx --replicas=2 回滚应用1kubectl rollout undo deployments/my-nginx]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSON 模式验证]]></title>
    <url>%2F2018%2F05%2F18%2FJSON-%E6%A8%A1%E5%BC%8F%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[后端接口参数校验在API开发中，我们需要对数据的格式做检查，我们的思路，有两种，一种，在程序中通过条件语句进行判断，二，在切面对数据整体做拦截检查，第二种处理思想要高级些，也是我们常用的处理方法。那么怎么实现呢？目前的项目中集成了一个object-check的库，通过在yaml或json文件中配置数据的Schema，然后在路由层中加载这个Schema 例如:123456789101112131415var bodyChecker = require(&apos;object-checker&apos;).bodyCheckMiddleware;router.post(&apos;/api/providers/my-apps/do/add&apos;, authMid.requireSignIn(), bodyChecker(BODY_SCHEMA.app.add), appsAPICtrl.addApp);#yaml schemaapp: add: newData: name: $minLength: 1 $maxLength: 512 这是我们项目中现在的处理思想，但是对于错误输入使用的是统一的错误输出模版。在来看下一个通用的处理方式,参考JSON Schema标准。 ajv的处理方式例子：12345678910111213141516171819202122232425262728293031323334const Ajv = require(&apos;ajv&apos;);let schema = &#123; type: &apos;object&apos;, required: [&apos;username&apos;, &apos;email&apos;, &apos;password&apos;], properties: &#123; username: &#123; type: &apos;string&apos;, minLength: 4 &#125;, email: &#123; type: &apos;string&apos;, format: &apos;email&apos; &#125;, password: &#123; type: &apos;string&apos;, minLength: 6 &#125;, age: &#123; type: &apos;integer&apos;, minimum: 0 &#125;, sex: &#123; enum: [&apos;boy&apos;, &apos;girl&apos;, &apos;secret&apos;], default: &apos;secret&apos; &#125;, &#125;&#125;;let ajv = new Ajv();let validate = ajv.compile(schema);let valid = validate(data);if (!valid) console.log(validate.errors); 以上处理方式发现报错都是统一，怎么实现个性化错误输出呢？引入一个包ajv-errors，在scheme中，添加errorMessage这个属性，用法示例：123456789101112131415var schema = &#123; type: &apos;object&apos;, required: [&apos;foo&apos;, &apos;bar&apos;], properties: &#123; foo: &#123; type: &apos;integer&apos; &#125;, bar: &#123; type: &apos;string&apos; &#125; &#125;, errorMessage: &#123; type: &apos;should be an object&apos;, // will not replace internal &quot;type&quot; error for the property &quot;foo&quot; required: &#123; foo: &apos;should have an integer property &quot;foo&quot;&apos;, bar: &apos;should have a string property &quot;bar&quot;&apos; &#125; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[实现一个redis客户端]]></title>
    <url>%2F2018%2F05%2F16%2F%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AAredis%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[开发背景学习一门编程语言，最快捷的方式就是学习了基本语法之后，能够实现一个中型的项目，这样对技术的提升有很大的帮助。针对go语言学习，计划以redis的sdk作为入门练习项目。关于实现这个项目，参考node.js的sdk实现，为了降低开发的难度，先实现系统架构图，要求耦合度低，然后逐个功能模块分解实现。借鉴别人好的设计实现思想，拒绝闭门造车。在架构上力求解耦，模块化。 知识准备在开始完成这个项目之前，需要先了解两方面知识，1. redis通信协议 2. 连接池的实现,在这个项目中，将使用这两个概念来完成该项目。 理解redis通信协议协议是通信的机制的一种规范，通过这种规范，可以被程序高效的识别。那么redis客户端和服务端的通信协议是怎么规定的，知道了这个协议规范，我们就可以编写程序解析出结果。 请求协议1234567891011121314151617*&lt;参数数量&gt; CR LF$&lt;参数 1 的字节数量&gt; CR LF&lt;参数 1 的数据&gt; CR LF...$&lt;参数 N 的字节数量&gt; CR LF&lt;参数 N 的数据&gt; CR LF例如：*3$3SET$5mykey$7myvalue&quot;*3\r\n$3\r\nSET\r\n$5\r\nmykey\r\n$7\r\nmyvalue\r\n&quot; 以上是客户端，发送请求协议的规范，它是建立在tcp协议之上的。 回复协议 作用 说明 状态回复 （status reply）的第一个字节是 “+” 错误回复 （error reply）的第一个字节是 “-“ 整数回复 （integer reply）的第一个字节是 “:” 批量回复 （bulk reply）的第一个字节是 “$” 多条批量回复 （multi bulk reply）的第一个字节是 “*” 以上对redis的协议做了简单的说明，将以上内容转化为程序语言后，就实现了redis功能的核心模块。 连接池的实现]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux 下 MySQL 密码强制修改]]></title>
    <url>%2F2018%2F05%2F09%2FLinux-%E4%B8%8B-MySQL-%E5%AF%86%E7%A0%81%E5%BC%BA%E5%88%B6%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[一、停掉mysql服务1$service mysqld stop 二、启动mysql，禁止权限验证12#在mysql安装目录的bin目录下执行(&amp;后台执行)$/usr/local/mysql/bin/mysqld_safe --skip-grant-tables &amp; 三、本地登录，更改密码12345678910#本地 localhost登录无需密码$mysql -u root#切换数据库$mysql&gt;use mysql;#更改密码$mysql&gt;update user set password=password(&quot;newpasswd&quot;) where user=&quot;root&quot;;#刷新权限$mysql&gt;flush privileges;#退出$mysql&gt;\q 四、启动mysql 停掉安全模式启动的服务 123456#查询mysql是否启动$ps aux | grep &quot;mysql&quot;#如果发现 有 --skip-grant-tables 类似的进程 找到其 PID kill掉#然后在 kill掉其他进程#PID : 用户名后面的 数字为PID$kill -9 PID 正常启动mysql 12#普通直接安装$service mysqld start 登录测试 12#输入密码$mysql -uroot -p]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份]]></title>
    <url>%2F2018%2F05%2F09%2Fmysql%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#!/bin/bash# 以下配置信息请自己修改mysql_user=&quot;USER&quot; #MySQL备份用户mysql_password=&quot;PASSWORD&quot; #MySQL备份用户的密码mysql_host=&quot;localhost&quot;mysql_port=&quot;3306&quot;mysql_charset=&quot;utf8&quot; #MySQL编码backup_db_arr=(&quot;db1&quot; &quot;db2&quot;) #要备份的数据库名称，多个用空格分开隔开 如(&quot;db1&quot; &quot;db2&quot; &quot;db3&quot;)backup_location=/var/www/mysql #备份数据存放位置，末尾请不要带&quot;/&quot;,此项可以保持默认，程序会自动创建文件夹expire_backup_delete=&quot;ON&quot; #是否开启过期备份删除 ON为开启 OFF为关闭expire_days=3 #过期时间天数 默认为三天，此项只有在expire_backup_delete开启时有效# 本行开始以下不需要修改backup_time=`date +%Y%m%d%H%M` #定义备份详细时间backup_Ymd=`date +%Y-%m-%d` #定义备份目录中的年月日时间backup_3ago=`date -d &apos;3 days ago&apos; +%Y-%m-%d` #3天之前的日期backup_dir=$backup_location/$backup_Ymd #备份文件夹全路径welcome_msg=&quot;Welcome to use MySQL backup tools!&quot; #欢迎语# 判断MYSQL是否启动,mysql没有启动则备份退出mysql_ps=`ps -ef |grep mysql |wc -l`mysql_listen=`netstat -an |grep LISTEN |grep $mysql_port|wc -l`if [ [$mysql_ps == 0] -o [$mysql_listen == 0] ]; then echo &quot;ERROR:MySQL is not running! backup stop!&quot; exitelse echo $welcome_msgfi# 连接到mysql数据库，无法连接则备份退出mysql -h$mysql_host -P$mysql_port -u$mysql_user -p$mysql_password &lt;&lt;enduse mysql;select host,user from user where user=&apos;root&apos; and host=&apos;localhost&apos;;exitendflag=`echo $?`if [ $flag != &quot;0&quot; ]; then echo &quot;ERROR:Can&apos;t connect mysql server! backup stop!&quot; exitelse echo &quot;MySQL connect ok! Please wait......&quot; # 判断有没有定义备份的数据库，如果定义则开始备份，否则退出备份 if [ &quot;$backup_db_arr&quot; != &quot;&quot; ];then #dbnames=$(cut -d &apos;,&apos; -f1-5 $backup_database) #echo &quot;arr is ($&#123;backup_db_arr[@]&#125;)&quot; for dbname in $&#123;backup_db_arr[@]&#125; do echo &quot;database $dbname backup start...&quot; `mkdir -p $backup_dir` `mysqldump -h$mysql_host -P$mysql_port -u$mysql_user -p$mysql_password $dbname --default-character-set=$mysql_charset | gzip &gt; $backup_dir/$dbname-$backup_time.sql.gz` flag=`echo $?` if [ $flag == &quot;0&quot; ];then echo &quot;database $dbname success backup to $backup_dir/$dbname-$backup_time.sql.gz&quot; else echo &quot;database $dbname backup fail!&quot; fi done else echo &quot;ERROR:No database to backup! backup stop&quot; exit fi # 如果开启了删除过期备份，则进行删除操作 if [ &quot;$expire_backup_delete&quot; == &quot;ON&quot; -a &quot;$backup_location&quot; != &quot;&quot; ];then #`find $backup_location/ -type d -o -type f -ctime +$expire_days -exec rm -rf &#123;&#125; \;` `find $backup_location/ -type d -mtime +$expire_days | xargs rm -rf` echo &quot;Expired backup data delete complete!&quot; fi echo &quot;All database backup success! Thank you!&quot; exitfi]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Flow]]></title>
    <url>%2F2018%2F05%2F09%2FGit-Flow%2F</url>
    <content type="text"><![CDATA[一、Git Flow 简介git flow是一种围绕项目开发对分支管理进行的一种规范,便于多人高效的协作。常见的有三种模型。 － Git flow 项目始终存在两个并行的分支，开发分支和主分支,主分支用于对外版本发布，开发分支主要进行日常的阶段开发，围绕，这个开发分支，存在三种短期的分支123**功能分支（feature branch）****补丁分支（hotfix branch）****预发分支（release branch）** 这种分支管理方式，很清晰的明了，但不利于持续发布。 Github flow第一种flow不利于持续发布，在github这种分支管理中，优化改进了该缺点。该种分支管理只存在一个主分支 具体流程如下: 根据需求，从master拉出新分支，不区分功能分支或补丁分支。 新分支开发完成后，或者需要讨论的时候，就向master发起一个pull request（简称PR） Pull Request是一个通知,采用会话机制 Pull Request被接受，合并进master，重新部署后，原来你拉出来的那个分支就被删除 github 这种分支管理模型符合了持续集成的需要 Git Commit Message规范在整个 Git Flow 中，commit message 也是必不可少的一部分；一个良好且统一的 commit message 有助于代码审计以及 review 等 规范参考Angular 社区规范 git commit message工具使用针对 Git 的 commit message 目前已经有了成熟的生成工具，比较有名的为 commitizen-cli 工具，其采用 node.js 编写，执行 git cz 命令能够自动生成符合 Angular 社区规范的 commit message；不过由于其使用 node.js 编写，所以安装前需要安装 node.js，因此可能不适合其他非 node.js 的项目使用；这里推荐一个基于 shell 编写的 Git-toolkit，安装此工具后执行 git ci 命令进行提交将会产生交互式生成 Angular git commit message 格式的提交说明 以上工具主要是为了规范项目提交的message。具体的使用说明，请自行参考项目文档展开进行学习。]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发一个npm包]]></title>
    <url>%2F2018%2F05%2F09%2F%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAnpm%E5%8C%85%2F</url>
    <content type="text"><![CDATA[npm账号注册登录 官网（https://www.npmjs.com/）注册账号 第一次注册的时候，没有注册成功，页面显示了一个邮箱地址和一串字符码，不管三七二十一的，就将该码发送到所示的邮箱，然后收到一封邮件。 Your request (35691) has been received. Our support hours are Monday through Friday, 9:00AM - 6:00PM PST, excluding US holidays. Your request is being reviewed by our support staff and we’ll be responding soon. To add additional comments, reply to this email. 然后在早上又重新的注册了下，就成功了。 开发自己的包 确定包名通过npm install 所起的包名,进行验证，报错，提示没有该包，那么就可以使用该包名了 开发代码我的第一个包是对一个存在的包做升级处理，代码测试通过后 package.json文件这个文件包含了包的相关信息，包名，依赖库，版本,main配置，协议等相关信息 README.mdreadme.md作为一个包重要的使用说明信息，也是不可缺少的一部分，readme的描述清晰度，直接关系到，人们对该包的使用情况。 发布安装1npm publish --access=public 注意 源要切换到官方的源，第三方淘宝源可能会报错]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对log4.js做格式化输出]]></title>
    <url>%2F2018%2F05%2F08%2F%E5%AF%B9log4.js%E5%81%9A%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[开发背景在公司的devops平台构建中，日志作为重要的一环，将系统的应用日志通过logdash接入第三方监控平台，再接入即时通信平台，从而实现对运行系统的实时监控。之前系统的日志使用的log4并对log4的输出文本做了改写。现在要按照一定的日志标准接入运维的日志系统。日志标准，运维定的是json格式,如下: 参数名 说明 示例 cc_timestamp 时间戳，精确到毫秒 1522317520698 message 日志内容 Creating order, order no. 1234567890 level 日志等级，DEBUG, WARNING, INFO, ERROR INFO app 应用名称，用于区分不同应用 usermaster 安照表中的内容对log进行格式化输出，项目使用的log4.js这个日志包，查了下文档，这个无法支持定制化的日志展示，查了很资料，都无法满足这一需要，有一个bunyan-extend的库，主要用来做json化日志输出的，但这个并不能满足定制化的key的要求，另外，项目又对log4.js做了进一步的包装，为了减少不必要麻烦，只能自己动手写轮子了。改写策略，要保证，不修改现有的log体系，只对log4的输出做格式化处理。 log4.js源码分析阅读了下log4.js的源码，核心代码不是太复杂，主要逻辑流程: 通过getLogger实例化一个logger对象 通过appenders加载日志输出的事件处理函数 通过事件监听，触发appenders事件处理函数 12345// 核心代码appenderList = appenders[ALL_CATEGORIES];appenderList.forEach(function(appender) &#123; loggers[loggerCategoryName].addListener(&quot;log&quot;, appender);&#125;); 现在的问题，就是针对appender进行改造了,appender的结构如下：123function(loggingEvent) &#123; consoleLog(layout(loggingEvent, timezoneOffset)); &#125;; 现在的所有的问题，都集中到layout上了，只要对layout做定制化处理，就达到我们最终的目标。对layout的改造最终形式为1234567var obj = &#123; app: &apos;itcloudlab&apos;, level: loggingEvent.level.levelStr, cc_timestamp: loggingEvent.startTime.getTime(), message: loggingEvent.data&#125;var str = JSON.stringify(obj); 以上，代码的清晰思路已经出来了，因为，时间比较紧张，真对改问题，我的处理思路是对layout做死值配置，而且，修改了log4的输入方式。 对log4的扩展这样的处理，基本满足了项目的需要，但是这种写死程序的方式，很不值得推荐，程序要有足够的健壮性。在此，理一下扩展性。抽个时间，把代码完善一下，希望可以merge到log4.js这个开源库中。 log4.js的配置文件，是通过appenders进行配置的，通过它作为扩展的入口，添加log输出类型,type－&gt; json，再，添加可以item选项,{name:”itcloudlab”, “msg”: “日志内容”, “time”: 时间, “levle”: info }，如果，存在就覆盖原有的key。 思路很简单，思路有了，具体的代码实现，等有空了，好好的理一下逻辑，再做完善。]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[minikube 本地部署运行 kubernetes 实例初试]]></title>
    <url>%2F2018%2F05%2F04%2Fminikube-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E8%BF%90%E8%A1%8C-kubernetes-%E5%AE%9E%E4%BE%8B%E5%88%9D%E8%AF%95%2F</url>
    <content type="text"><![CDATA[k8s作为目前最火的容器集群管理工具，总让人蠢蠢欲试，但一搞到集群总会让人望而止步，多台基础设施环境的主机，如果没有丰富的运维经验，很难驾驭的了。好在，k8s发布了一个迷你版的环境，可以直接跑在我们的电脑上。 那么，就一起来学习下这个迷你版的k8s吧 kubernetes 介绍 kubernetes是什么? Kubernetes 是 Google 开源的容器集群管理系统，它构建在目前流行的 Docker 技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等一整套功能。 Minikube是什么? Minikube 是一个可以在本地轻松运行 Kubernetes 的工具。Minikube 会在您的笔记本电脑中的虚拟机上运行一个单节点的 Kubernetes 集群，以便用户对 Kubernetes 进行试用或者在之上进行 Kubernetes 的日常开发。 实验目标 在Mac OS 10.11.6系统下安装Minikube 在Minikube上部署一个应用 对应用做持续更新 minikube 安装 使用 curl 下载和安装 Minikube 最新发布的版本 123curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 &amp;&amp; \ chmod +x minikube &amp;&amp; \ sudo mv minikube /usr/local/bin/ 安装 Hypervisor 123brew install docker-machine-driver-xhyvesudo chown root:wheel $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyvesudo chmod u+s $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve 注意以上下载有被墙的风险，被墙，请寻找其它下载源进行安装 kubectl 安装 通过 Homebrew 安装1brew install kubectl 安装docker参考docker官网进行安装，此处不在分解 启动minikube 启动minikube 1minikube start --vm-driver=xhyve 设置 Minikube 上下文 1kubectl config use-context minikube 验证 1kubectl cluster-info 注意： 若启动失败，可以执行rm -rf ~/.minikube，重新安装 创建应用镜像 创建应用代码使用文件 server.js 保存在 hellonode 的文件夹中 123456789var http = require(&apos;http&apos;);var handleRequest = function(request, response) &#123; console.log(&apos;Received request for URL: &apos; + request.url); response.writeHead(200); response.end(&apos;Hello World!&apos;);&#125;;var www = http.createServer(handleRequest);www.listen(8080); 建 Ddocker 容器镜像 1234FROM node:6.9.2EXPOSE 8080COPY server.js .CMD node server.js 设置Minikube Docker 守护程序 1eval $(minikube docker-env) 注意： 当您不再希望使用这个 Minikube 主机时，您可以通过运行 eval $(minikube docker-env -u) 来撤消此更改。 构建镜像1docker build -t hello-node:v1 . 部署 创建 Deployment 1234567891011$kubectl run hello-node --image=hello-node:v1 --port=8080#查看 Deployment：$kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEhello-node 1 1 1 1 3m# 查看 Pod：$kubectl get podsNAME READY STATUS RESTARTS AGEhello-node-714049816-ztzrb 1/1 Running 0 6m 创建 Service 默认情况下，Pod 只能通过 Kubernetes 集群中的内部 IP 地址访问。要使得 hello-node 容器可以从 Kubernetes 虚拟网络的外部访问，您必须将 Pod 暴露为 Kubernetes Service。 在您的开发机器中，可以使用 kubectl expose 命令将 Pod 暴露给公网： 1kubectl expose deployment hello-node --type=LoadBalancer 访问服务 1minikube service hello-node 查看应用日志 1$kubectl logs &lt;POD-NAME&gt; 总结以上，安装过程中，遇到的一些问题，大都和网络有关，最好使用科学上网，以免安装不顺利 本人在安装过程中，遇到一个问题，发现 hello-minikube 服务并没有成功启动123$ kubectl get podsNAME READY STATUS RESTARTS AGEhello-minikube-598805112-3bzmf 0/1 ContainerCreating 0 15s 发现 hello-minikube 的状态一直是 ContainerCreating，并且 READY 为 0/1 通过minikube logs查看发现gcr.io/google_containers/pause-amd64:3.0这个镜像下载失败，被墙的原因吧 这个本地设置有代理，可能命令行的原因吧 替代方案123456# 替换镜像$ docker pull visenzek8s/pause-amd64:3.0$ docker tag visenzek8s/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0# 显式设置拉取策略为 IfNotPresent$ kubectl run hello-node --image=hello-node:v1 --port=8080 --image-pull-policy=IfNotPresent]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker命令行清单]]></title>
    <url>%2F2018%2F05%2F04%2Fdocker%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[1.环境信息相关 info 使用方法：docker info 使用说明: 显示本地docker配置信息 version 使用方法：docker version 使用说明： 显示 Docker 的版本号，API 版本号，Git commit，Docker 客户端和后台进程的 Go 版本号。 2.系统运维相关 attach 使用方法： docker attach [OPTIONS] CONTAINER 使用说明： 在开发应用的过程中运用这个命令可以随时观察容器內进程的运行状况 build 使用方法： docker build [OPTIONS] PATH | URL | - 使用说明： 这个命令是从源码构建新 Image 的命令 commit 使用方法： docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 使用说明： 这个命令的用处在于把有修改的 container 提交成新的 Image，然后导出此 Imange 分发给其他场景中调试使用。 cp 使用方法： cp CONTAINER:PATH HOSTPATH 使用说明： 使用 cp 可以把容器內的文件复制到 Host 主机上 diff 使用方法： docker diff CONTAINER 使用说明： diff 会列出3种容器内文件状态变化 images 使用方法： docker images [OPTIONS] [NAME] 使用说明： 显示镜像列表 export/ import / save / load 使用方法： 1234docker export red_panda &gt; latest.tardocker import URL|- [REPOSITORY[:TAG]]docker save IMAGEdocker load 使用说明： 导出或加载容器的镜像文件 inspect 使用方法： 1docker inspect CONTAINER|IMAGE [CONTAINER|IMAGE...] 使用说明： 查看容器运行时详细信息的命令 kill 使用方法： docker kill [OPTIONS] CONTAINER [CONTAINER…] 使用说明： 杀掉容器的进程 port 使用方法： docker port CONTAINER PRIVATE_PORT 使用说明： 打印出 Host 主机端口与容器暴露出的端口的 NAT 映射关系 pause / unpause 使用方法： docker pause CONTAINER 使用说明： 使用 cgroup 的 freezer 顺序暂停、恢复容器里的所有进程 ps 使用方法： docker ps [OPTIONS] 使用说明： docker ps 打印出正在运行的容器 rm 使用方法： docker rm [OPTIONS] CONTAINER [CONTAINER…] 使用说明： 删除指定的容器 rmi 使用方法： docker rmi IMAGE [IMAGE…] 使用说明： 指定删除 Image 文件 run 使用方法： docker run [OPTIONS] IMAGE [COMMAND] [ARG…] 使用说明： 这个命令是核心命令，可以配置的子参数详细解释可以通过 docker run –help 列出。 start / stop / restart 使用方法： docker start CONTAINER [CONTAINER…] 使用说明： 这组命令可以开启（两个：start，restart），停止（一个：stop）一个容器。 tag 使用方法： docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] 使用说明： 组合使用用户名，Image 名字，标签名来组织管理Image top 使用方法： docker top CONTAINER [ps OPTIONS] 使用说明： 显示容器內运行的进程。 wait 使用方法： docker wait CONTAINER [CONTAINER…] 使用说明： 阻塞对指定容器的其他调用方法，直到容器停止后退出阻塞。 rename 使用方法： docker rename CONTAINER NEW_NAME 使用说明： 重新命名一个容器。 stats 使用方法： docker stats [OPTIONS] [CONTAINER…] 使用说明： 实时显示容器资源使用监控指标。 update 使用方法： docker update [OPTIONS] CONTAINER [CONTAINER…] 使用说明： 更新一或多个容器实例的 IO、CPU、内存，启动策略参数。 exec 使用方法： docker exec [OPTIONS] CONTAINER COMMAND [ARG…] 使用说明： 在运行中容器中运行命令。 deploy 使用方法： docker deploy [OPTIONS] STACK 使用说明： 部署新的 stack 文件，两种格式 DAB 格式和 Compose 格式 create 使用方法： docker create [OPTIONS] IMAGE [COMMAND] [ARG…] 使用说明： 可以创建容器但并不执行它。 3.日志信息相关 events 使用方法： docker events [OPTIONS] 使用说明： 打印容器实时的系统事件。 history 使用方法： docker history [OPTIONS] IMAGE 使用说明： 打印指定 Image 中每一层 Image 命令行的历史记录。 logs 使用方法： docker logs CONTAINER 使用说明： 批量打印出容器中进程的运行日志。 4.Docker Hub服务相关 login/ logout 使用方法： docker login [OPTIONS] [SERVER]docker logout [SERVER] 使用说明： 登录登出 Docker Hub 服务。 pull / push 使用方法： docker push NAME[:TAG] 使用说明： 通过此命令分享 Image 到 Hub 服务或者自服务的 Registry 服务。 search 使用方法： docker search TERM 使用说明： 通过关键字搜索分享的 Image 5. 后台进程]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令清单]]></title>
    <url>%2F2018%2F05%2F04%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[由上图可知，代码管理也就是在以上四个空间处理。 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 1.新建代码库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 2.配置123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot; 3.增加/删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 4.代码提交123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 5.分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 6.标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 7.查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 8.远程管理1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 9.撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 10.其他12# 生成一个可供发布的压缩包$ git archive]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git生成多个ssh-keygen]]></title>
    <url>%2F2018%2F05%2F03%2FGit%E7%94%9F%E6%88%90%E5%A4%9A%E4%B8%AAssh-keygen%2F</url>
    <content type="text"><![CDATA[作为新时代的开发者，大家一般会拥有自己的Github工程。同时公司又提供单独gitlab服务器，所以经常会遇到需要在同一设备下配置多个ssh key的情况，下述会阐述如何进行设置操作： 第一步：生成指定名称的秘钥1$ ssh-keygen 第二步：配置config文件在~/.ssh文件夹下创建config文件,添加以下内容12Host 192.168.0.45IdentityFile ~/.ssh/id_rsa.idss 字段 说明 Host 远程主机地址 IdentityFile 私钥的文件路径及文件名称 User 用户 Port 远程主机上连接的端口号 HostName 要登录的真实主机名。数字IP地址也是允许的 第三步：复制新生成的公钥到服务器复制公钥到github或相关gitlab,ssh key配置项中 第四步：修改相关用户配置12$ git config user.name &quot;your name&quot;$ git config user.email &quot;your email&quot;]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git代码回滚]]></title>
    <url>%2F2018%2F05%2F03%2Fgit%E4%BB%A3%E7%A0%81%E5%9B%9E%E6%BB%9A%2F</url>
    <content type="text"><![CDATA[场景1 糟了，我刚把不想要的代码，commit到本地仓库中了，但是还没有做push操作！ 文件修改未执行git add操作 12$git checkout fileName$git checkout . 同时对多个文件执行了git add操作，但本次只想提交其中一部分文件 1234$ git add *$ git status# 取消暂存$ git reset HEAD &lt;filename&gt; 文件执行了git add操作，但想撤销对其的修改 1234# 取消暂存git reset HEAD fileName# 撤销修改git checkout fileName 修改的文件已被git commit，但想再次修改不再产生新的Commit 123# 修改最后一次提交$ git add sample.txt$ git commit --amend -m&quot;说明&quot; 已在本地进行了多次git commit操作，现在想撤销到其中某次Commit 1git reset [--hard|soft|mixed|merge|keep] [commit|HEAD] 场景2 彻底完了，刚线上更新的代码出现问题了，需要还原这次提交的代码！ 注意：已进行git push，即已推送到“远程仓库”中。我们将已被提交到“远程仓库”的代码还原操作叫做“回滚”！注意：对远程仓库做回滚操作是有风险的，需提前做好备份和通知其他团队成员！ 通过tag发布 1$git checkout &lt;tag&gt; 回到当前的分支 1$git checkout &lt;branch_name&gt; 撤销指定文件到指定版本 1234# 查看指定文件的历史版本git log &lt;filename&gt;# 回滚到指定commitIDgit checkout &lt;commitID&gt; &lt;filename&gt; 删除最后一次远程提交 1234567# 方式一：使用revert$git revert HEAD$git push origin master# 方式二：使用reset$git reset --hard HEAD^$git push origin master -f 二者区别：revert是放弃指定提交的修改，但是会生成一次新的提交，需要填写提交注释，以前的历史记录都在；reset是指将HEAD指针指到指定提交，历史记录中不会出现放弃的提交记录。]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下命令集]]></title>
    <url>%2F2018%2F05%2F03%2FLinux%E4%B8%8B%E5%91%BD%E4%BB%A4%E9%9B%86%2F</url>
    <content type="text"><![CDATA[linux命令行作为开发运维一项必备的技能，熟练的使用命令行工具，可以提高日常开发效率和分析排错的能力。此文档主要为平时常使用的一些命令集合整理，方便自己查阅。 git相关的12# 打包增量代码$git archive --format=tar.gz --output ~/www-csrf.tar.gz HEAD $(git diff 66fa65b6499f860d88a7e69698454deddcbd5db6 a6f8faadf9dfce35edd044b76baba2ad91adc3ec --name-only) 网络排错1234567891011121314151617181920# 查看端口使用情况$netstat -tunpl# 查看连接数$lsof -n|awk &apos;&#123;print $2&#125;&apos;|sort|uniq -c|sort -nr| grep &lt;进程ID&gt;# 网络链接状态检查$nc ip port#追踪dns解析$nslookup www.baidu.comServer: 202.96.209.5Address: 202.96.209.5#53Non-authoritative answer:www.baidu.com canonical name = www.a.shifen.com.Name: www.a.shifen.comAddress: 115.239.211.112Name: www.a.shifen.comAddress: 115.239.210.27 系统处理奇技淫巧1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253＃ 产生随机的十六进制数，n 是字符数openssl rand -hex n＃ 在当前 shell 里执行一个文件里的命令source /path/to/filename＃ 截取变量的前五个字符$&#123;variable:0:5&#125;＃ 用 wget 抓取完整的网站目录结构，存放到本地目录中wget -r --no-parent --reject &quot;index.html*&quot; http://hostname/ -P /home/user/dirs＃ 一次创建多个目录mkdir -p /home/wdxtub/&#123;test0,test1,test2&#125;＃ 测试硬盘写入速度dd if=/dev/zero of=/tmp/output.img bs=8k count=256k; rm -rf /tmp/output.img＃ 测试硬盘读取速度hdparm -Tt /dev/sda＃ 获取文本的 md5echo -n &quot;test&quot; | md5sum＃ 获取 HTTP 头信息curl -I http://wdxtub.com＃ 显示所有 tcp4 监听端口netstat -tln4 | awk &apos;&#123;print $4&#125;&apos; | cut -f2 -d: | grep -o &apos;[0-9]*&apos;＃ 查看命令的运行时间time command＃ 查看所有的环境变量export＃ 文件内容对比cmp file1 file2＃ 内容前面会显示行号cat -n file＃ 查看 22 端口现在运行的程序lsof -i:22＃ 显示 abc 进程现在打开的文件lsof -c abc＃ 看进程号为 12 的进程打开了哪些文件lsof -p 12// etcd设置base64值curl -vvv http://xxx.xxx.xxx.xxx:2379/v2/keys/env-config -XPUT -d value=&quot;$(cat ../config/config.yaml | base64)&quot; 修改国内源1234567891011121314151617$cp /etc/apt/sources.list /etc/apt/sources.list_backup$cat &gt; /etc/apt/sources.list &lt;&lt; EOF#aliyundeb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverseEOF# 更换源$sed -i &apos;s/http:\/\/archive\.ubuntu\.com\/ubuntu\//http:\/\/mirrors\.163\.com\/ubuntu\//g&apos; /etc/apt/sources.list node.js项目脚本启动文件1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashlog_file=&quot;$PWD/auto-update-server.log&quot;function log() &#123; echo &apos;&apos; 2&gt;&amp;1 | tee -a $log_file echo -e &quot;\033[1;36m$1\033[1;0m&quot; 2&gt;&amp;1 | tee -a $log_file&#125;run_time=`date &quot;+%Y-%m-%d %H:%M:%S&quot;`log &quot;===== 脚本启动 ($run_time)=====&quot;git checkout .log &apos;更新remote&apos;git remote update 2&gt;&amp;1 | tee -a $log_filegit fetch --tags 2&gt;&amp;1 | tee -a $log_fileif [ $# -eq 1 ]; then log &quot;切换到分支：$1&quot; git checkout $1 2&gt;&amp;1 | tee -a $log_filefilog &apos;获取最新代码&apos;git pull 2&gt;&amp;1 | tee -a $log_filelog &apos;安装第三方包&apos;npm install 2&gt;&amp;1 | tee -a $log_filelog &quot;关闭内部站服务器&quot;pm2 delete internal 2&gt;&amp;1 | tee -a $log_filelog &apos;启动内部站服务器&apos;pm2 start app/app.js --name internal 2&gt;&amp;1 | tee -a $log_filesleep 5log &apos;当前内部站服务器状态：&apos;pm2 status 2&gt;&amp;1 | tee -a $log_file go语言修改工作目录12345678910111213141516171819202122232425#!/usr/bin/env bashset -eif [ ! -f install.sh ]; then echo &apos;install must be run within its container folder&apos; 1&gt;&amp;2 exit 1fiCURDIR=`pwd`OLDGOPATH=&quot;$GOPATH&quot;export GOPATH=&quot;$CURDIR&quot;export GOBIN=if [ ! -d log ]; then mkdir logfigofmt -w -s srcgo install dreamgoexport GOPATH=&quot;$OLDGOPATH&quot;echo &apos;finished&apos; mysql脚本123456789101112131415161718192021222324252627282930313233343536373839#开启远程登录grant all privileges on *.* to &apos;user&apos;@&apos;%&apos; identified by &apos;passwd&apos; with grant option;#创建数据库create database DB;#创建用户insert into mysql.user(Host,User,Password) values(&quot;localhost&quot;,&quot;user&quot;,password(&quot;passwd&quot;));#删除用户DELETE FROM user WHERE user=&quot;username&quot; and HOST=&quot;localhost&quot;;#修改指定用户密码update mysql.user set password=password(&apos;new passwd&apos;) where user=&quot;username&quot; and host=&quot;localhost&quot;;#用户授权grant all privileges on DB.* to &apos;user&apos;@&apos;localhost&apos; identified by &apos;passwd&apos;;grant select,update on DB.* to &apos;user&apos;@&apos;localhost&apos; identified by &apos;passwd&apos;;#刷新权限flush privileges;#数据库导出mysqldump -uUSRENAME -pPASSWD DATABASE &gt; DATABASE.sql#数据库导出(只导出表结构 -d)mysqldump -uUSRENAME -pPASSWD -d DATABASE &gt; DATABASE.sql#数据库导入#1.切换数据库use DATABASE;#2.设置编码set names utf8;#3.执行导入操作source /home/abc/abc.sql;#直接导入mysql -uUSERNAME -p DATABASE &lt; DATABASE.sql shell编程]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linx cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈前后端分离的认识]]></title>
    <url>%2F2018%2F05%2F03%2F%E8%B0%88%E8%B0%88%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E8%AE%A4%E8%AF%86%2F</url>
    <content type="text"><![CDATA[当你面试的时候，无法绕开的一个话题就是，前端开发和后端开发更甚全栈开发。这是职业上的划分，那么前端，后端怎么在项目上进行界定的。这个针对不同的项目，表现不同的形式。简单的说，前端偏于页面展示，后端则重于业务数据处理。 分工的发生早期的系统架构，主要是C/S，服务端进行业务处理，客户端通过网络链接和server端进行通信，客户端主要用于数据的展示，服务端则进行业务数据的处理，clinet端和server都使用的是同一种编程语言，client端也是一种运行于服务器上的程序，所以采用同服务端程序相同的处理语言。后来发展演变出了一种新的架构模型B/S模型，这种模型是基于http协议进行通信的，客户端是一个存在的容器，通过URI得到服务端的资源内容，然后下载到浏览器中进行渲染，展示出我们所看到的内容。 这时就出现了前后端的分工，前端主要工作在浏览器中，也就是工作成果最终被展现在浏览器中。浏览器编程，主要需要的技能，CSS，html，javascript三项基本技能。 什么是前后端分离？在针对这个话题，每个人的认识都不一样，大都程序猿认为，基于浏览器渲染的SPA应用通过ajax调用后端接口获取数据，在浏览器层面进行组装渲染。这种划分方式是严格安照物理来划分的。 如果，按照业务来划分，我们可以分为数据层，和展示层,也就是后端主要从事业务数据处理，前端则主要进行页面展示的处理。 基于以上的分层，就需要我们使用node.js做全栈开发了。每层之间定义通信的协议。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊node.js]]></title>
    <url>%2F2018%2F05%2F03%2F%E8%81%8A%E4%B8%80%E8%81%8Anode-js%2F</url>
    <content type="text"><![CDATA[接触node.js有三年有余了，期间也参与过一些大的node项目，但回过头，感觉还是需要对这个编程框架好好的整理下，已达到深入的地方。 node.js结构 由上图可以看出,node.js分三层1.Node.js 标准库，这部分是由 Javascript 编写的，即我们使用过程中直接能调用的 API。在源码中的 lib 目录下可以看到 2.Node bindings，这一层是 Javascript 与底层 C/C++ 能够沟通的关键，前者通过 bindings 调用后者，相互交换数据。实现在 node.cc 最底层是node.js运行的核心。 V8支撑了js的运行时，提供了js高效的执行环境 Libuv：它为 Node.js 提供了跨平台，线程池，事件池，异步 I/O 等能力，是 Node.js 主要的特点 重点对libuv展开它是一个对开发者友好的工具集，包含定时器，非阻塞的网络 I/O，异步文件系统访问，子进程等功能。它封装了 Libev、Libeio 以及 IOCP，保证了跨平台的通用性,屏蔽了底层的差异性。 先来看一个例子，打开一个文件1234var fs = require(&apos;fs&apos;);fs.open(&apos;./test.txt&apos;, &quot;w&quot;, function(err, fd) &#123; //..do something&#125;); 代码的调用过程大致可描述为：lib/fs.js → src/node_file.cc → uv_fs由以上可以得知，node.js通过V8将Javascript解释,然后由 C/C++ 来执行真正的系统调用,可以看出Node.js 并不是一门语言，而是一个平台。 异步、非阻塞I/O当我们将 I/O 操作的请求传达给 Libuv 之后，Libuv 开启线程来执行这次 I/O 调用，并在执行完成后，传回给 Javascript 进行后续处理 I/O 包括文件 I/O 和 网络 I/O Libuv 官网的图中，我们可以看到，文件 I/O，DNS 等操作，都是依托线程池（Thread Pool）来实现的。而网络 I/O 这一大类，包括：TCP、UDP、TTY 等，是由 epoll、IOCP、kqueue 来具体实现的。 我们其实对 Node.js 的单线程一直有个误会,事实上，它的单线程指的是自身Javascript 运行环境的单线程，Node.js并没有给 Javascript 执行时创建新线程的能力，最终的实际操作，还是通过 Libuv 以及它的事件循环来执行的。这也就是为什么 Javascript 一个单线程的语言，能在 Node.js 里面实现异步操作的原因，两者并不冲突。 事件驱动说到，事件驱动，对于前端来说，并不陌生。事件，是一个在 GUI 开发时很常用的一个概念，常见的有鼠标事件，键盘事件等等。在异步的多种实现中，事件是一种比较容易理解和实现的方式。 一些可能的瓶颈首先，文件的 I/O 方面，用户代码的运行，事件循环的通知等，是通过 Libuv 维护的线程池来进行操作的，它会运行全部的文件系统操作。既然这样，我们抛开硬盘的影响，对于严谨的 C/C++ 来说，这个线程池一定是有大小限制的。官方默认给出的大小是 4。当然是可以改变的。在启动时，通过设置 UV_THREADPOOL_SIZE 来改变这个值即可。不过，最大也只能是 128，因为这个是涉及到内存占用的。 对于网络 I/O 方面，以 Linux 系统下来说，网络 I/O 采用的是 epoll 这个异步模型。它的优点是采用了事件回调的方式，大大降低了文件描述符的创建（Linux下什么都是文件）。 在每次调用 epoll_wait 时，实际返回的是就绪描述符的数量，根据这个值，去 epoll 指定的数组里面取对应数量的描述符，是一种 内存映射 的方式，减少了文件描述符的复制开销。 上面提到的 epoll 指定的数组，它的大小即可监听的数量大小，它在不同的系统下，有不同的默认值，可见这里 epoll create。 有了大小的限制，还远不够，为了保证运行的稳定，防止你在调用 epoll 函数时，指针越界，导致内存泄漏。还会用到另外一个值 maxevents，它是 epoll_wait 所能处理的最大数量，在调用 epoll_wait 时可以指定。一般情况下小于创建时（epoll_create）的数组大小，当然，也可以设置的比 size 大，不过应该没什么用。可以想到如果就绪的事件很多，超过了 maxevents，那么超出的事件就要等待前面的事件处理完成，才可以继续，可能会导致效率的下降。 在这种情况下，你可能会担心事件会丢失。其实，是不会丢失的，它会通过 ep_collect_ready_items 将这些事件保存在一个队列中，在下一个 epoll_wait 再进行通知。 Node.js 不适合做什么由以上的总结，node.js主线程是单线程的，一旦它进行大量的计算操作，回导致整个事件循环阻塞，所以不建议使用node.js处理cpu密集型计算 参考Node.js 探秘：初识单线程的 Node.js]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node.js 同步获取网络数据]]></title>
    <url>%2F2018%2F05%2F03%2Fnode-js-%E5%90%8C%E6%AD%A5%E8%8E%B7%E5%8F%96%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[背景项目要上devops，配置中心是整个平台重要的一环，通过它可以自由的配置项目需要的一些配置项。传统服务器部署的方式，通过系统环境变量指定系统的配置项，在程序中通过环境变量指定的地址进行读取。修改配置项，需要远程登录主机，通过vim编辑器修改。现在的改进方案是，将通过etcd作为配置中心，在容器启动时配置环境变量配置etcd对应项目的key的接口，在程序中通过调用接口获取配置信息，将配置中心作为独立的一块进行管理，方便了部署。针对该方案，需要对项目的代码进行修改，将原有的通过环境变量加载配置文件的方式修改为，从配置中心拉取数据的方式。修改方案很简单，将原有的读取文件修改为读取网络文件（linux理念一切皆文件）。 问题点确定了修改了方案，那么接下来就是行动了，项目使用的是node.js，都知道node.js最大的编程特点，处理I/O操作时，通过异步回调无阻塞的方式进行的。作为一个全局使用的配置文件项，这里不能使用异步的方式进行处理，为什么？后续的业务处理需要依赖读取的配置项，也就是这里需要阻塞，否则，后续业务获取的配置项都为undefined。node.js 在处理这种I／O操作都是异步非阻塞的，现在，怎么让的同步阻塞呢？ 处理的办法真对以上的node.js同步编程进行搜索，得到的结果大都是promise,async的结果，将异步转化为同步的处理的处理方式，但这种方式只是书面，只是为了方便我们进行程序开发，符合我们处理事情的习惯，但程序后台执行的顺序依旧是异步的方式，也就是说程序执行是没有阻塞的，这种处理方式肯定不能满足我们的解决以上问题的需要？最后通过锲而不舍的搜索，找到了这样的一个库sync-request可以解决该问题，它阻塞的javascript的引擎的执行，正是我们需要的。通过它获取etcd接口配置，拉取文件内容 基本用法12345678// 用法1var request = require(&apos;sync-request&apos;);var res = request(&apos;GET&apos;, &apos;https://example.com&apos;, &#123; headers: &#123; &apos;user-agent&apos;: &apos;example-user-agent&apos;, &#125;,&#125;);console.log(res.getBody());]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>同步</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd做配置中心的使用]]></title>
    <url>%2F2018%2F04%2F29%2Fetcd%E5%81%9A%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[存在的问题 配置文件的作用配置文件是项目中不可缺少的一部分，它的作用主要用来，灵活配置项目的一些通用配置项。方便部署时切换环境，不用动到代码层面。 项目做法在部署时配置一个环境变量 1export config_path = &quot;/home/dev/config/config.yaml&quot; 在项目中通过load加载该文件，同时读取代码中的基础配置文件，将二者获取的内容进行合并，作为最终项目需要的配置项，供项目中其它代码使用。 devops环境上的存在的痛点将所负责的项目迁到devops，配置这块还是按照现在的做法部署，将配置文件随代码库一起提交，在容器中设置环境变量。这样的做法有个很大的问题，就是测试环境和开发环境的切换，需要每次都修改配置代码，这样很容易出问题。 解决的方式etcd是go语言开发的一个分布式key－value数据库，主要用来做服务发现和配置中心等。在devops环境中，通过使用该组件，我们可以轻松的解决了以上的问题。 搭建ectd容器 将部署容器的环境变量设置为etcd的获取key的接口http://host:2379/v2/keys/config 通过etcd接口向etcd中设置值此处，需要注意的是，向配置文件内容base64后存入etcd中，在代码中，需要将获取的值base64做转码 存在的问题 存在着重大的安全问题，使用的原生的ectd的接口，没有安全验证，缺乏安全性 通过命令向配置中心添加配置文件，同样不安全，另外这种设定的方式也很不直观，不小心配置错了，拍错难度有些大]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go实现session]]></title>
    <url>%2F2018%2F04%2F28%2Fgo%E5%AE%9E%E7%8E%B0session%2F</url>
    <content type="text"><![CDATA[session是什么？众所周知，http协议是一个无状态的协议,每一次请求都是无状态的，所以，无法标记用户的行为，因此，我们需要一个存储来帮我们解决这件事情。于时，cookie和session便出现了。session是服务端做存储管理，cookie是浏览器端的存储。但session不能独立使用，需要客户端存储的sessionId配合使用，sessionId用于标识session中存储的对应的信息。 session实现思想session的基本原理是由服务器为每个会话维护一份信息数据，客户端和服务端依靠一个全局唯一的标识来访问这份数据，以达到交互的目的。当用户访问Web应用时，服务端程序会随需要创建session，这个过程可以概括为三个步骤 生成全局唯一标识符（sessionid) 开辟数据存储空间,做数据持久化处理 将session的全局唯一标示符发送给客户端 真对以上三点，我们展开分解，第一步很简单，生成唯一标识符]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次使用vue开发的流程]]></title>
    <url>%2F2018%2F04%2F27%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8vue%E5%BC%80%E5%8F%91%E7%9A%84%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[开发前准备 项目开发规约的制定（参考腾讯前端团队规约http://alloyteam.github.io/CodeGuide/#naming） git管理方式 使用easymock搭建API服务 官方文档学习 github搜索资源 页面功能组件划分 确定开发工具的版本 脚手架构建 vue-cli构建项目基础结构 项目目录结构划分 移动端UI框架,使用mint-ui 页面路由切换,页面间跳转实现及参数传递 axios请求API封装 过渡动画处理 vuex使用 打包部署 mint-ui按需加载 赖加载修改 打包nginx静态部署 优化及一些坑 数据初始化 路由参数变化，模版不变处理 工具函数的封装及使用]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab实现持续集成]]></title>
    <url>%2F2018%2F04%2F27%2Fgitlab%E5%AE%9E%E7%8E%B0%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[背景最近，公司搞了devops，在所负责的项目中，也搞过docker容器化部署，使用的是jenkins做为构建工具，公司采用是gitlab runner做为构建工具。画了张项目结构图 结构体系大致的流程 提交代码到gitlab中，触发gitlab ci在runner机器中执行ci脚本，完成docker镜像的制作，push到私有部署的私有镜像库中 在rancher中配置容器启动命令拉取镜像，服务启动 整个流程分为两步，第一步被称为CI(持续集成)，第二步被称为CD(持续部署)，在该方案中使用runner作为构建工具。使用rancher作为容器管理工具。 组件介绍gitlabgitlab 是一个git的代码托管管理工具，具有强大的管理功能。在gitlab 8.0以后gitlab ci集成在gitlab中。通过在ci中注册的服务器来执行构建脚本。 runnerGitLab Runner 是一个开源项目， 它用来运行你定制的任务（jobs）并把结果返回给 GitLab。 GitLab Runner 配合GitLab CI（GitLab 内置的持续集成服务） 协调完成任务。 docker私有镜像库docker私有镜像库用于存放docker的镜像，对镜像进行私有化部署. runcherruncher是一个开源的企业级容器部署及管理平台 搭建 基础环境环境主机名 | 用处 | 配置–|–|–gitlab | gitlab | 2核4Grunner1 | runner | 1核4Grancher-server | rancher| 2核4Gagent1 | agent1 | 1核2Gagent2 | agent2 | 1核2G 系统：使用ubuntu14.04，更换国内源 docker安装将以上五台机器安装docker参考官网ubuntu14.04 下docker安装 gitlab搭建在此使用docker进行gitlab的安装 12345678910111213# 拉取gitlab镜像$docker pull gitlab/gitlab-ce:latest＃ 启动docker容器# 创建/u1/gitlab用于将容器中的数据导出做持久化$mkdir /u1/gitlab$docker run \ --publish 443:443 --publish 80:80 --publish 22:22 \ --name gitlab \ --volume /u1/gitlab/config:/etc/gitlab \ --volume /u1/gitlab/logs:/var/log/gitlab \ --volume /u1/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce 管理配置gitlabhttp://ip 就进入 gitlab 访问界面 runner安装及注册 1234567891011121314151617181920＃安装# For Debian/Ubuntu$sudo apt-get install gitlab-ci-multi-runner＃注册$ sudo gitlab-ci-multi-runner registerPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )https://mygitlab.com/ciPlease enter the gitlab-ci token for this runnerxxx-xxx-xxxPlease enter the gitlab-ci description for this runnermy-runnerINFO[0034] fcf5c619 Registering runner... succeededPlease enter the executor: shell, docker, docker-ssh, ssh?dockerPlease enter the Docker image (eg. ruby:2.1):node:4.5.0INFO[0037] Runner registered successfully. Feel free to start it, but if it&apos;srunning already the config should be automatically reloaded! docker私有镜像库搭建 12$docker pull registry:2.1.1$docker run -d -v /opt/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry:2.1.1 runcher服务部署 1docker run -d --restart=unless-stopped -p 8080:8080 rancher/server rancher使用 设置访问权限由于任何访问服务器的人都可以打开Rancher界面，我们需要先进行权限控制，在系统管理-访问控制里选择local，设置个账号密码。 添加环境添加多个环境分配给不同的用户权限，可以把测试环境、生产环境分离开进行管理，根据页面的说明操作即可。 添加主机填写配置信息，主机上安装Rancher的客户端，让Rancher好发现并管理该主机 添加应用docker化部署需要运行的系统]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前后端分离框架csrf防御.md]]></title>
    <url>%2F2018%2F04%2F27%2F%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%A1%86%E6%9E%B6csrf%E9%98%B2%E5%BE%A1%2F</url>
    <content type="text"><![CDATA[前端时间，项目被阿里的安全团队检测，报告存在csrf安全问题，csrf这个攻击方式，以前只是简单的了解，没有深入进入，现在被告知存在这个安全风险，作为已经运行了两三的年的成熟系统，现在真对这个问题，修改，难度还是有些大的。 项目的基本框架项目的web框架使用的是node.js的express框架，功能操作通过提供接口实现，页面在服务端通过ejs模版引擎渲染。前端通过封装的ajax对接口进行调用，完成功能操作。 业务架构项目是一个进行云计算培训的教育平台，分为学习站和管理站，注册登录用户在学习站进行云资源课程的创建和学习。管理站主要针对管理员和课程创作者使用，进行内容录入。 存在的csrf问题调查针对这样的一个运行稳定了的系统，进行csrf防护，难度还是有些大的，csrf的防护最好要在框架层面解决。根据csrf的原理，一个主要的防御策略就是针对有数据增，删，改操作的要统一做随机数验证。根据这点要求，对项目功能接口做调查，发现一些有一些存在数据库操作的接口使用了get请求，如：删除功能等等。针对这个存在的问题，我的策略是将其变为post请求方式。总后对post请求做同一的随机数验证。 解决问题的思路真对以上的get请求，项目代码命名结构等比较规范，我的策略是将get请求改为post请求，大概有五六十个（主要集中在管理站），这个只完成了第一步，然后对post请求在切面做随记数验证。 实现的思路在express框架中存在一个csrf中间件，这个中间件的实现思路 在服务端生成一个随记数token，将其存储到session中，同时将改参数交给前端 在请求的时候把这个token加入到请求数据或者头信息中，传给后端 在服务端拦截验证session和客户端所传的token 由于项目没有使用session，使用了redis存储服务端的信息，这里考虑使用redis存储这个token。既然数据不存储在服务端，那么就要存储到客户端。也许你已经想到了，通过cookie来实现。 服务端产生一个随记数token，对该token进行散列算法生成tokenStr字符串。 将这两个token都设置到cookie中，返回到前端。 前端发起请求的时候，从cookie中获取token，把这个token加入到请求数据或者头信息中，发送到服务端 在服务端对 token做同样的散列算法，验证token的合法性通过该思路对post请求进行改造。 代码实现 实现一个csrf的中间件,在随记数的实现和验证方法等使用了一个csrf的第三方包csrf 1234567891011121314151617181920212223242526272829303132var Tokens = require(&apos;csrf&apos;);exports.csrfCheck = function csrfCheck(req, res, next) &#123; var opts = &#123;&#125;; var tokens = new Tokens(opts); var ignoreMethods = [&apos;GET&apos;, &apos;HEAD&apos;, &apos;OPTIONS&apos;]; var curSecret = req.cookies._csrf; var curToken = req.headers[&apos;x-csrf-token&apos;] || req.query[&apos;csrfToken&apos;]; if (ignoreMethods.indexOf(req.method) == -1) &#123; if (!curToken || !curSecret) &#123; return next(new _e(&apos;EUserForbidden&apos;, &apos;invalid csrf token&apos;)); &#125; //验证token if (!tokens.verify(curSecret, curToken)) &#123; return next(new _e(&apos;EUserForbidden&apos;, &apos;invalid csrf token&apos;)); &#125; &#125; //生成token var secret = tokens.secretSync(); res.cookie(&apos;_csrf&apos;, secret, &#123; httpOnly: true &#125;); // 设置token_key值 var token = tokens.create(secret); res.cookie(&apos;_csrf-token&apos;, token, &#123; httpOnly: false &#125;) return next();&#125; 在前端ajax的请求中，添加csrf token 1234567891011121314151617181920212223242526272829303132333435363738util.apiPostJSON = function apiPostJSON(options) &#123; var fullUrl = options.query ? toolkit.appendQuery(options.url, options.query) : options.url; var postData = options.body ? JSON.stringify(options.body) : undefined; var headers = &#123; &apos;x-auth-token&apos;: localStorage.getItem(&apos;xAuthToken&apos;) || undefined, &apos;x-csrf-token&apos;: $.cookie(&apos;_csrf-token&apos;) || undefined &#125;; $.ajax(&#123; dataType : &apos;json&apos;, contentType: &apos;application/json&apos;, type : &apos;POST&apos;, url : fullUrl, headers : headers, data : postData, success: function(j, s, jqXHR) &#123; // 默认成功时刷新页面 if (!options.success) &#123; toolkit.reload(); return; &#125; if (&apos;function&apos; === typeof options.success) &#123; options.success(jqXHR.responseJSON, jqXHR.status); &#125; &#125;, error: function(jqXHR) &#123; if (&apos;function&apos; === typeof options.error) &#123; options.error(jqXHR.responseJSON, jqXHR.status); &#125; &#125;, complete: function(jqXHR) &#123; if (&apos;function&apos; === typeof options.complete) &#123; options.complete(jqXHR.responseJSON, jqXHR.status); &#125; &#125;, &#125;);&#125;;]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>csrf</tag>
        <tag>前后端分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go学习笔记1－知识点导图]]></title>
    <url>%2F2018%2F04%2F23%2Fgo%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%EF%BC%8D%E7%9F%A5%E8%AF%86%E7%82%B9%E5%AF%BC%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[go语言总览知识体系 go是由goole出品的编程语言，在并发处理上了使用了一种新的理念,不同于java的多线程实现并发，也不同于node.js基于事件的方式通过异步回调的机制。它使用在学术上被称为CSP模型，通过协程的方式实现并发编程。在语言特点上，它是一种强类型的语言，语法简单，易于上手，执行效率高效。 本系列将按照以上的知识体系图进行展开 1. 语言的安装，运行环境将介绍mac环境下go安装,语言执行环境介绍，go语言内置相关命令 2. 使用sublime test3搭建开发环境以sublime text3作为开发工具，搭建go开发环境 3. 基本数据类型go语言的基本数据类型, 整形，浮点型，字符串，数组登进行展开 4. 切片go语言中一种特有的数据类型，可以理解为变长数组 5. mapmap在其他语言体系中，我们称为hash table 或字典型, 6. 控制结构任何一种编程语言都实现有两种控制结构，判断和循环，那么go语言是怎样实现的？有什么不同，在该篇内容进行展开 7. 函数函数是go语言编程的一个重要概念,在go中，我们将函数看作一种数据类型，在go中，通过关键字var，type, func声明的，都可以被称为一种类型 8. 结构和方法这篇内容主要用来实现面向对象编程的，go语言的面向对象编程在语法上要比较简单 9. 包管理包管理是实现模块化编程的重要体现，go的模块化管理又有其特有的特色 10. 接口和反射接口是约定的一种规约，实现了接口方法的实例就是该接口的实例。 11. 错误处理go语言没有try/catch的异常处理方式，它实现了另一种机制defer-panic-and-recover 12. goroutine和channel该篇内容是整个体系的重中之中，也是go语言的一大特色,通过通信方式进行变量共享，而非共享变量进行通信 13. 基于共享变量的并发编程go同样实现了java共享变量的多线程编程,在该篇中将进行展开 14. 实战实现一个docker客户端通过一个实战项目实现docker的客户端，实现一个业务分发的简单编程框架]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
</search>
